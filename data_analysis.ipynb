{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f45b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/07 23:02:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/07/07 23:02:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session initialized successfully!\n",
      "Spark version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import json\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Rearc_Data_Quest\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session initialized successfully!\")\n",
    "print(f\"Spark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e57c6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 37,002\n",
      "+-----------+----+------+-----+--------------+\n",
      "|  series_id|year|period|value|footnote_codes|\n",
      "+-----------+----+------+-----+--------------+\n",
      "|PRS30006011|1995|   Q01|  2.6|          NULL|\n",
      "|PRS30006011|1995|   Q02|  2.1|          NULL|\n",
      "|PRS30006011|1995|   Q03|  0.9|          NULL|\n",
      "|PRS30006011|1995|   Q04|  0.1|          NULL|\n",
      "|PRS30006011|1995|   Q05|  1.4|          NULL|\n",
      "|PRS30006011|1996|   Q01| -0.2|          NULL|\n",
      "|PRS30006011|1996|   Q02| -0.3|          NULL|\n",
      "|PRS30006011|1996|   Q03| -0.1|          NULL|\n",
      "|PRS30006011|1996|   Q04|  0.2|          NULL|\n",
      "|PRS30006011|1996|   Q05| -0.1|          NULL|\n",
      "+-----------+----+------+-----+--------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 11\n",
      "+---------+-------------+-------+----+----------+-------------+\n",
      "|ID Nation|       Nation|ID Year|Year|Population|  Slug Nation|\n",
      "+---------+-------------+-------+----+----------+-------------+\n",
      "|  01000US|United States|   2023|2023| 332387540|united-states|\n",
      "|  01000US|United States|   2022|2022| 331097593|united-states|\n",
      "|  01000US|United States|   2021|2021| 329725481|united-states|\n",
      "|  01000US|United States|   2020|2020| 326569308|united-states|\n",
      "|  01000US|United States|   2019|2019| 324697795|united-states|\n",
      "|  01000US|United States|   2018|2018| 322903030|united-states|\n",
      "|  01000US|United States|   2017|2017| 321004407|united-states|\n",
      "|  01000US|United States|   2016|2016| 318558162|united-states|\n",
      "|  01000US|United States|   2015|2015| 316515021|united-states|\n",
      "|  01000US|United States|   2014|2014| 314107084|united-states|\n",
      "+---------+-------------+-------+----+----------+-------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "#Loading both the CSV file from Part 1 (time series data) and JSON file from Part 2 (population data).\n",
    "\n",
    "# Load CSV file without schema first to handle whitespace in headers\n",
    "df_timeseries_raw = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .csv(\"tmp/pr.data.0.Current\")\n",
    "\n",
    "# Clean column names by stripping whitespace\n",
    "clean_columns = [col_name.strip() for col_name in df_timeseries_raw.columns]\n",
    "\n",
    "# Rename columns to remove whitespace\n",
    "df_temp = df_timeseries_raw\n",
    "for old_col, new_col in zip(df_timeseries_raw.columns, clean_columns):\n",
    "    if old_col != new_col:\n",
    "        df_temp = df_temp.withColumnRenamed(old_col, new_col)\n",
    "\n",
    "# Now cast to proper types and select only needed columns\n",
    "df_timeseries = df_temp.select(\n",
    "    col(\"series_id\").cast(StringType()),\n",
    "    col(\"year\").cast(IntegerType()),\n",
    "    col(\"period\").cast(StringType()),\n",
    "    col(\"value\").cast(DoubleType()),\n",
    "    col(\"footnote_codes\").cast(StringType())\n",
    ")\n",
    "\n",
    "# Clean whitespace from data values\n",
    "df_timeseries = df_timeseries.select([\n",
    "    trim(col(c)).alias(c) if c in [\"series_id\", \"period\"] else col(c) \n",
    "    for c in df_timeseries.columns\n",
    "])\n",
    "\n",
    "print(f\"Total rows: {df_timeseries.count():,}\")\n",
    "df_timeseries.show(10)\n",
    "\n",
    "# Load JSON population data\n",
    "with open(\"tmp/population_data.json\", \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# Extract the data array from JSON\n",
    "population_data = json_data[\"data\"]\n",
    "\n",
    "# Define schema for population data\n",
    "population_schema = StructType([\n",
    "    StructField(\"ID Nation\", StringType(), True),\n",
    "    StructField(\"Nation\", StringType(), True),\n",
    "    StructField(\"ID Year\", IntegerType(), True),\n",
    "    StructField(\"Year\", StringType(), True),\n",
    "    StructField(\"Population\", LongType(), True),\n",
    "    StructField(\"Slug Nation\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame from JSON data\n",
    "df_population = spark.createDataFrame(population_data, population_schema)\n",
    "\n",
    "print(f\"Total rows: {df_population.count():,}\")\n",
    "df_population.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4e8264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population data for 2013-2018:\n",
      "+-------+----------+\n",
      "|ID Year|Population|\n",
      "+-------+----------+\n",
      "|   2013| 311536594|\n",
      "|   2014| 314107084|\n",
      "|   2015| 316515021|\n",
      "|   2016| 318558162|\n",
      "|   2017| 321004407|\n",
      "|   2018| 322903030|\n",
      "+-------+----------+\n",
      "\n",
      "POPULATION STATISTICS (2013-2018):\n",
      "+---------------+------------------+\n",
      "|mean_population|    std_population|\n",
      "+---------------+------------------+\n",
      "|   3.17437383E8|4257089.5415293295|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the dataframe from the population data API (Part 2)\n",
    "# generate the mean and the standard deviation of the annual US population across the years [2013, 2018] inclusive.\n",
    "population_stats = df_population \\\n",
    "    .filter((col(\"ID Year\") >= 2013) & (col(\"ID Year\") <= 2018)) \\\n",
    "    .select(\"ID Year\", \"Population\")\n",
    "\n",
    "print(\"Population data for 2013-2018:\")\n",
    "population_stats.orderBy(\"ID Year\").show()\n",
    "\n",
    "stats_result = population_stats \\\n",
    "    .select(\"Population\") \\\n",
    "    .agg(\n",
    "        mean(\"Population\").alias(\"mean_population\"),\n",
    "        stddev(\"Population\").alias(\"std_population\")\n",
    "    )\n",
    "\n",
    "print(\"POPULATION STATISTICS (2013-2018):\")\n",
    "\n",
    "stats_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ca1c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample yearly sums:\n",
      "+-----------+----+-------------------+\n",
      "|  series_id|year|         yearly_sum|\n",
      "+-----------+----+-------------------+\n",
      "|PRS30006011|1995|                7.1|\n",
      "|PRS30006011|1996|               -0.5|\n",
      "|PRS30006011|1997|                4.4|\n",
      "|PRS30006011|1998|                4.2|\n",
      "|PRS30006011|1999| -7.699999999999999|\n",
      "|PRS30006011|2000|               -1.5|\n",
      "|PRS30006011|2001|              -22.9|\n",
      "|PRS30006011|2002|              -35.9|\n",
      "|PRS30006011|2003|-23.900000000000002|\n",
      "|PRS30006011|2004|               -6.9|\n",
      "+-----------+----+-------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Using the dataframe from the time-series (Part 1), For every series_id, find the best year: the year with the max/largest sum of \"value\" for all quarters in that year. \n",
    "# Generate a report with each series id, the best year for that series, and the summed value for that year. \n",
    "yearly_sums = df_timeseries \\\n",
    "    .groupBy(\"series_id\", \"year\") \\\n",
    "    .agg(sum(\"value\").alias(\"yearly_sum\"))\n",
    "\n",
    "print(\"Sample yearly sums:\")\n",
    "yearly_sums.orderBy(\"series_id\", \"year\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd76009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST YEAR FOR EACH SERIES (Top 20):\n",
      "+-----------+----+------------------+\n",
      "|  series_id|year|        yearly_sum|\n",
      "+-----------+----+------------------+\n",
      "|PRS30006011|2022|              20.5|\n",
      "|PRS30006012|2022|              17.1|\n",
      "|PRS30006013|1998|           705.895|\n",
      "|PRS30006021|2010|              17.7|\n",
      "|PRS30006022|2010|12.399999999999999|\n",
      "|PRS30006023|2014|503.21600000000007|\n",
      "|PRS30006031|2022|              20.5|\n",
      "|PRS30006032|2021|              17.1|\n",
      "|PRS30006033|1998|           702.672|\n",
      "|PRS30006061|2022|              37.0|\n",
      "|PRS30006062|2021|              31.6|\n",
      "|PRS30006063|2024|           646.748|\n",
      "|PRS30006081|2021|              24.4|\n",
      "|PRS30006082|2021|              24.4|\n",
      "|PRS30006083|2021|           110.742|\n",
      "|PRS30006091|2002|              43.3|\n",
      "|PRS30006092|2002| 44.39999999999999|\n",
      "|PRS30006093|2013| 514.1560000000001|\n",
      "|PRS30006101|2020|              33.5|\n",
      "|PRS30006102|2020|              36.2|\n",
      "+-----------+----+------------------+\n",
      "only showing top 20 rows\n",
      "Total unique series analyzed: 282\n"
     ]
    }
   ],
   "source": [
    "# Find the year with maximum sum for each series_id\n",
    "window_spec = Window.partitionBy(\"series_id\").orderBy(desc(\"yearly_sum\"))\n",
    "\n",
    "best_years = yearly_sums \\\n",
    "    .withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "    .filter(col(\"rank\") == 1) \\\n",
    "    .select(\"series_id\", \"year\", \"yearly_sum\") \\\n",
    "    .orderBy(\"series_id\")\n",
    "\n",
    "print(\"BEST YEAR FOR EACH SERIES (Top 20):\")\n",
    "best_years.show(20)\n",
    "\n",
    "print(f\"Total unique series analyzed: {best_years.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c299ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for PRS30006032, Q01:\n",
      "+-----------+----+------+-----+\n",
      "|  series_id|year|period|value|\n",
      "+-----------+----+------+-----+\n",
      "|PRS30006032|1995|   Q01|  0.0|\n",
      "|PRS30006032|1996|   Q01| -4.2|\n",
      "|PRS30006032|1997|   Q01|  2.8|\n",
      "|PRS30006032|1998|   Q01|  0.9|\n",
      "|PRS30006032|1999|   Q01| -4.1|\n",
      "|PRS30006032|2000|   Q01|  0.5|\n",
      "|PRS30006032|2001|   Q01| -6.3|\n",
      "|PRS30006032|2002|   Q01| -6.6|\n",
      "|PRS30006032|2003|   Q01| -5.7|\n",
      "|PRS30006032|2004|   Q01|  2.0|\n",
      "|PRS30006032|2005|   Q01| -0.5|\n",
      "|PRS30006032|2006|   Q01|  1.8|\n",
      "|PRS30006032|2007|   Q01| -0.8|\n",
      "|PRS30006032|2008|   Q01| -3.5|\n",
      "|PRS30006032|2009|   Q01|-21.0|\n",
      "|PRS30006032|2010|   Q01|  3.2|\n",
      "|PRS30006032|2011|   Q01|  1.5|\n",
      "|PRS30006032|2012|   Q01|  2.5|\n",
      "|PRS30006032|2013|   Q01|  0.5|\n",
      "|PRS30006032|2014|   Q01| -0.1|\n",
      "+-----------+----+------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Using both dataframes from Part 1 and Part 2, generate a report that will provide the value for series_id = PRS30006032 and period = Q01 \n",
    "# and the population for that given year (if available in the population dataset) \n",
    "target_series = \"PRS30006032\"\n",
    "target_period = \"Q01\"\n",
    "\n",
    "filtered_ts = df_timeseries \\\n",
    "    .filter((col(\"series_id\") == target_series) & (col(\"period\") == target_period)) \\\n",
    "    .select(\"series_id\", \"year\", \"period\", \"value\")\n",
    "\n",
    "print(f\"Data for {target_series}, {target_period}:\")\n",
    "filtered_ts.orderBy(\"year\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d74d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined report PRS30006032, Q01:\n",
      "+-----------+----+------+-----+----------+\n",
      "|  series_id|year|period|value|Population|\n",
      "+-----------+----+------+-----+----------+\n",
      "|PRS30006032|1995|   Q01|  0.0|      NULL|\n",
      "|PRS30006032|1996|   Q01| -4.2|      NULL|\n",
      "|PRS30006032|1997|   Q01|  2.8|      NULL|\n",
      "|PRS30006032|1998|   Q01|  0.9|      NULL|\n",
      "|PRS30006032|1999|   Q01| -4.1|      NULL|\n",
      "|PRS30006032|2000|   Q01|  0.5|      NULL|\n",
      "|PRS30006032|2001|   Q01| -6.3|      NULL|\n",
      "|PRS30006032|2002|   Q01| -6.6|      NULL|\n",
      "|PRS30006032|2003|   Q01| -5.7|      NULL|\n",
      "|PRS30006032|2004|   Q01|  2.0|      NULL|\n",
      "|PRS30006032|2005|   Q01| -0.5|      NULL|\n",
      "|PRS30006032|2006|   Q01|  1.8|      NULL|\n",
      "|PRS30006032|2007|   Q01| -0.8|      NULL|\n",
      "|PRS30006032|2008|   Q01| -3.5|      NULL|\n",
      "|PRS30006032|2009|   Q01|-21.0|      NULL|\n",
      "|PRS30006032|2010|   Q01|  3.2|      NULL|\n",
      "|PRS30006032|2011|   Q01|  1.5|      NULL|\n",
      "|PRS30006032|2012|   Q01|  2.5|      NULL|\n",
      "|PRS30006032|2013|   Q01|  0.5| 311536594|\n",
      "|PRS30006032|2014|   Q01| -0.1| 314107084|\n",
      "+-----------+----+------+-----+----------+\n",
      "only showing top 20 rows\n",
      "Records found: 31\n"
     ]
    }
   ],
   "source": [
    "combined_report = filtered_ts \\\n",
    "    .join(\n",
    "        df_population.select(\"ID Year\", \"Population\"),\n",
    "        filtered_ts.year == df_population[\"ID Year\"],\n",
    "        \"left\"\n",
    "    ) \\\n",
    "    .select(\"series_id\", \"year\", \"period\", \"value\", \"Population\") \\\n",
    "    .orderBy(\"year\")\n",
    "\n",
    "print(f\"Combined report {target_series}, {target_period}:\")\n",
    "combined_report.show()\n",
    "\n",
    "print(f\"Records found: {combined_report.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506232bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results...\n",
      "Population statistics saved\n",
      "Best years report saved\n",
      "Combined report saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"Saving results...\")\n",
    "\n",
    "# Save population statistics\n",
    "stats_result.coalesce(1).write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(f\"{output_dir}/population_stats\")\n",
    "\n",
    "print(\"Population statistics saved\")\n",
    "\n",
    "# Save best years report\n",
    "best_years.coalesce(1).write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(f\"{output_dir}/best_years\")\n",
    "\n",
    "print(\"Best years report saved\")\n",
    "\n",
    "# Save combined report\n",
    "combined_report.coalesce(1).write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(f\"{output_dir}/combined_report\")\n",
    "\n",
    "print(\"Combined report saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
